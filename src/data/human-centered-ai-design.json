{
  "title": "Human-Centered AI Design",
  "description": "Designing transparent, predictable AI experiences following Microsoft HAX guidelines",
  "categories": ["Transparency", "Agency", "Usability", "Trust"],
  "categoryColors": {
    "Transparency": "label-sky",
    "Agency": "label-orange",
    "Usability": "label-orchid",
    "Trust": "label-green"
  },
  "principles": [
    {
      "id": "make-the-ai-s-role-explicit",
      "title": "Make the AIâ€™s role explicit",
      "category": "Transparency",
      "icon": "mi/outline/info",
      "description": "Clearly show when AI is involved and what it does within the interaction flow.",
      "sources": [
        "building-trust-in-ai-the-role-of-transparency-and-accountability",
        "when-the-ai-sounds-confident-and-everyone-gets-nervous",
        "transparent-ai-in-customer-service-building-trust-with-customers"
      ]
    },
    {
      "id": "design-for-uncertainty",
      "title": "Design for uncertainty",
      "category": "Transparency",
      "icon": "mi/outline/help",
      "description": "Expose uncertainty so users understand confidence, risk, and limitations of AI outputs.",
      "sources": [
        "scope-services-when-in-doubt",
        "embrace-ai-s-uncertainty-in-ux",
        "ai-chatbots-discourage-error-checking",
        "ai-hallucinations",
        "ai-transparency-in-the-age-of-llms"
      ]
    },
    {
      "id": "provide-understandable-explanations",
      "title": "Provide understandable explanations",
      "category": "Transparency",
      "icon": "mi/outline/chat-bubble",
      "description": "Explain results in user-facing terms that support decisions, not model internals.",
      "sources": [
        "designing-ai-user-interfaces-that-foster-trust-and-transparency",
        "explainable-ai-ensuring-design-decisions-are-transparent-and-accountable",
        "ai-ux-design-creating-transparency-trust-in-ai-products"
      ]
    },
    {
      "id": "avoid-misleading-anthropomorphism",
      "title": "Avoid misleading anthropomorphism",
      "category": "Transparency",
      "icon": "mi/outline/person-off",
      "description": "Avoid human-like cues that inflate expectations or suggest intent or emotions.",
      "sources": [
        "breaking-the-illusion-the-case-against-anthropomorphizing-ai-systems",
        "daring-more-raw-ai-ness-a-critique-of-personified-voice-assistants",
        "rethinking-ai-anthropomorphism"
      ]
    },
    {
      "id": "preserve-user-agency",
      "title": "Preserve user agency",
      "category": "Agency",
      "icon": "mgg/ai-chatbot-outline",
      "description": "Ensure users remain the final decision-makers, with AI acting as support.",
      "sources": [
        "preserving-human-agency-ai-era",
        "preserving-user-control-ai-agents",
        "four-principles-of-explainable-artificial-intelligence"
      ]
    },
    {
      "id": "enable-meaningful-user-control",
      "title": "Enable meaningful user control",
      "category": "Agency",
      "icon": "mi/outline/how-to-reg",
      "description": "Let users modify, override, pause, or undo AI actions easily.",
      "sources": [
        "the-human-side-of-ai-control-and-choice",
        "designing-interfaces-that-let-users-disagree-with-ai",
        "let-me-decide-increasing-user-autonomy",
        "on-the-purpose-of-meaningful-human-control-of-ai",
        "meaningful-human-control-over-ai-systems-beyond-talking-the-talk"
      ]
    },
    {
      "id": "support-human-in-the-loop-interaction",
      "title": "Support human-in-the-loop interaction",
      "category": "Agency",
      "icon": "mi/outline/tune",
      "description": "Design AI workflows that allow continuous human supervision and input.",
      "sources": [
        "how-to-be-the-designer-in-the-ai-loop",
        "human-in-the-loop",
        "human-in-the-loop-design-when-ai-needs-a-teammate"
      ]
    },
    {
      "id": "handle-errors-and-failures-gracefully",
      "title": "Handle errors and failures gracefully",
      "category": "Usability",
      "icon": "mi/outline/error",
      "description": "Communicate AI errors clearly and offer safe recovery paths.",
      "sources": [
        "designing-for-recovery-and-forgiveness-after-ai-mistakes",
        "ai-assistance-in-enterprise-ux-design-workflows-enhancing-design-brief-creation-for-designers",
        "designing-for-ai-errors-turning-mistakes-into-user-friendly-solutions",
        "designing-ux-for-ai-errors-how-to-handle-failures-the-right-way",
        "provide-paths-forward-from-failure"
      ]
    },
    {
      "id": "adapt-to-user-context-and-expertise",
      "title": "Adapt to user context and expertise",
      "category": "Usability",
      "icon": "mi/outline/manage-accounts",
      "description": "Adjust AI behavior and feedback to user goals, skills, and situations.",
      "sources": [
        "progressive-disclosure-reduce-ai-token-usage-by-60",
        "creating-ai-that-adapts-to-user-context-and-goals",
        "progressive-disclosure-for-ai-agents",
        "dynamic-context-aware-prompt-recommendation-for-domain-specific-ai-applications",
        "human-centered-design-through-ai-assisted-usability-testing"
      ]
    },
    {
      "id": "respect-user-time-and-cognitive-load",
      "title": "Respect user time and cognitive load",
      "category": "Usability",
      "icon": "mi/outline/hourglass-empty",
      "description": "Reduce mental effort with clear, progressive, and concise AI output.",
      "sources": [
        "the-effect-of-interface-consistency-and-cognitive-load-on-user-performance-in-an-information-search-task",
        "scope-services-when-in-doubt",
        "ux-must-alleviate-the-cognitive-burden-of-time",
        "achieve-better-ux-and-design-usability-by-reducing-cognitive-load",
        "user-experience-design"
      ]
    },
    {
      "id": "design-for-trust-and-accountability",
      "title": "Design for trust and accountability",
      "category": "Trust",
      "icon": "mi/outline/verified-user",
      "description": "Make responsibility, provenance, and decision ownership transparent.",
      "sources": [
        "designing-for-responsible-trust-in-ai-systems",
        "ai-transparency-through-design-5-practical-lessons-from-the-field",
        "designing-ai-transparency-trust",
        "building-trust-in-ai-systems"
      ]
    },
    {
      "id": "set-appropriate-expectations",
      "title": "Set appropriate expectations",
      "category": "Transparency",
      "icon": "mi/outline/speed",
      "description": "Align messaging with real capabilities to prevent overtrust or misuse.",
      "sources": [
        "ai-ux-design-creating-transparency-trust-in-ai-products",
        "ai-transparency-through-design-5-practical-lessons-from-the-field",
        "designing-ai-transparency-trust",
        "human-centered-design-for-ai-enhancing-ux-of-ml-and-transparency",
        "artificial-intelligence-shapes-how-we-think-feel-and-behave"
      ]
    }
  ]
}
